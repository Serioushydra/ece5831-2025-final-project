{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214dbba7",
   "metadata": {},
   "source": [
    "# ECE-5831 Final Project — How to Run (final-project.ipynb)\n",
    "\n",
    "**Project:** Intelligent Ticket Triage for Customer Support Tickets  \n",
    "**Author:** Nikhil Patil (+ team)  \n",
    "\n",
    "This notebook is a *runner notebook* that shows the end-to-end process to:\n",
    "1) set up the environment, 2) fetch data (CFPB complaints), 3) run the demo app, and (optionally) 4) reproduce training.\n",
    "\n",
    "> ✅ Tip: After you run all cells, use **Kernel → Restart & Run All**, then **Save**. That ensures the notebook is \"executed\" for GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e66963",
   "metadata": {},
   "source": [
    "## 0) Project files expected in this repo\n",
    "\n",
    "- `app.py` (Streamlit demo)  \n",
    "- `model/` (your fine-tuned adapter weights directory)  \n",
    "- `EDA_and_Baseline.ipynb` (baseline experiments)  \n",
    "- `Finetuning.ipynb` (LoRA/PEFT finetuning)  \n",
    "- `requirements.txt` (recommended)  \n",
    "- `.env` (local only; **do not commit**)  \n",
    "\n",
    "If your adapter folder has a different name, update it in `app.py` (it uses `adapter_path = \"./model\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ea833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: run this cell to confirm you're in the repo root.\n",
    "import os, sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"Repo files:\", sorted([f for f in os.listdir('.') if not f.startswith('.')] )[:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835884ea",
   "metadata": {},
   "source": [
    "## 1) Create / activate a Python environment\n",
    "\n",
    "Run one of the options below in a terminal **from your repo folder**.\n",
    "\n",
    "### Option A — conda\n",
    "```bash\n",
    "conda create -n ece5831-final python=3.10 -y\n",
    "conda activate ece5831-final\n",
    "```\n",
    "\n",
    "### Option B — venv\n",
    "```bash\n",
    "python -m venv .venv\n",
    "# Windows:\n",
    ".venv\\Scripts\\activate\n",
    "# macOS/Linux:\n",
    "source .venv/bin/activate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL (recommended): create a requirements.txt if you don't already have one.\n",
    "# Run this cell ONCE (it will not overwrite an existing file).\n",
    "req_path = \"requirements.txt\"\n",
    "if not os.path.exists(req_path):\n",
    "    req = \"\\n\".join([\n",
    "        \"streamlit>=1.30\",\n",
    "        \"torch\",\n",
    "        \"transformers\",\n",
    "        \"peft\",\n",
    "        \"accelerate\",\n",
    "        \"bitsandbytes\",\n",
    "        \"python-dotenv\",\n",
    "        \"datasets\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"scikit-learn\",\n",
    "        \"matplotlib\",\n",
    "        \"seaborn\",\n",
    "    ]) + \"\\n\"\n",
    "    with open(req_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(req)\n",
    "    print(\"Created requirements.txt\")\n",
    "else:\n",
    "    print(\"requirements.txt already exists — leaving it unchanged.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6596846",
   "metadata": {},
   "source": [
    "## 2) Install dependencies\n",
    "\n",
    "In your terminal (with your environment activated):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "If you use CUDA, make sure you have a compatible PyTorch build.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d564b8a",
   "metadata": {},
   "source": [
    "## 3) Add your Hugging Face token safely (DO NOT commit it)\n",
    "\n",
    "Create a file named `.env` in the repo root:\n",
    "\n",
    "```text\n",
    "HUGGING_FACE_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "```\n",
    "\n",
    "Also create a `.gitignore` so `.env` never gets committed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/append a minimal .gitignore to protect secrets and large artifacts.\n",
    "gi_path = \".gitignore\"\n",
    "lines = []\n",
    "if os.path.exists(gi_path):\n",
    "    with open(gi_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "add = [\n",
    "    \".env\",\n",
    "    \"__pycache__/\",\n",
    "    \"*.pyc\",\n",
    "    \".venv/\",\n",
    "    \"venv/\",\n",
    "    \".ipynb_checkpoints/\",\n",
    "    \"*.pt\",\n",
    "    \"*.bin\",\n",
    "    \"*.safetensors\",\n",
    "    \"*.ckpt\",\n",
    "]\n",
    "changed = False\n",
    "for item in add:\n",
    "    if item not in lines:\n",
    "        lines.append(item)\n",
    "        changed = True\n",
    "\n",
    "if changed:\n",
    "    with open(gi_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines) + \"\\n\")\n",
    "    print(\"Updated .gitignore\")\n",
    "else:\n",
    "    print(\".gitignore already contains the recommended entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199f5f6",
   "metadata": {},
   "source": [
    "## 4) (Optional) Fetch the CFPB dataset\n",
    "\n",
    "You can download the CFPB consumer complaints dataset from the official site and place it in a `data/` folder.\n",
    "\n",
    "- CFPB dataset page: https://www.consumerfinance.gov/data-research/consumer-complaints/\n",
    "\n",
    "> If your baseline/finetuning notebooks already handle dataset loading, you can skip this step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd84d9",
   "metadata": {},
   "source": [
    "## 5) Run the Streamlit demo app\n",
    "\n",
    "This uses `app.py` in this repo. It loads a Llama-based sequence classification model + your PEFT adapter.\n",
    "\n",
    "In a terminal:\n",
    "\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "Streamlit will print a local URL (usually `http://localhost:8501`). Open it in your browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience: show the exact command you should run (copy/paste in a terminal).\n",
    "print(\"streamlit run app.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1408691",
   "metadata": {},
   "source": [
    "## 6) (Optional) Reproduce experiments\n",
    "\n",
    "Open and run these notebooks as needed:\n",
    "\n",
    "- `EDA_and_Baseline.ipynb` — EDA + baseline models\n",
    "- `Finetuning.ipynb` — LoRA/PEFT finetuning and saving adapter weights\n",
    "\n",
    "After finetuning, ensure your saved adapter directory is present at `./model/` (or update `app.py`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef4790",
   "metadata": {},
   "source": [
    "## 7) Final checklist before you push to GitHub\n",
    "\n",
    "- [ ] `final-project.ipynb` runs top-to-bottom\n",
    "- [ ] `.env` exists locally but is ignored by git\n",
    "- [ ] `README.md` contains links (report, slides, video, dataset, demo)\n",
    "- [ ] Big model weights are **not** committed (use a link or Git LFS if required)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
